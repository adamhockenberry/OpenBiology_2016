{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to users:\n",
    "This notebook / repo was intended to be provided to users to check the analysis of the Hockenberry et al. (2017) Open Biology paper. In its current form it serves that purpose.\n",
    "\n",
    "That being said, it's not exactly clean or really intended as a platform for extensions and analysis of novel datasets. More accurately, this code / these notebooks became a leviathan of just trying to cram everything into the right sized figures to carry the paper across the finish line. This paper was a discovery paper and not a tool, so all of the functions are in here and usable but they're buried within these libraries and not exactly clean. Feel free to email me if you'd like to actually analyze new datasets and I can provide you with a 1000x nicer notebook/set of functions to perform a basic analysis on your dataset of interest. Unfortunately the figures for an actual paper always get messier / more complex so much in this notebook might not be entirely useful for individuals. \n",
    "\n",
    "Also as of the last update to these notebooks, where I've ensured that everything runs properly and free of errors, I've noticed that this notebook makes pretty poor figures that need some adjustments to legends, axes, etc owing to updates undoubtedly in statsmodels, matplotlib, etc. Apologies but I leave this as an exercise to the user to debug if they want cleanliness. This notebook was created for openness and reproducibility only.\n",
    "\n",
    "**I stress, however, that if you want to use this type of analysis in any future work please reach out to me and I'd be ecstatic to collaborate and/or provide you with more up-to-date, readable, and user-friendly code that will be geared towards your specific dataset and present a cleaner analysis for those purposes. That code is not written but my familiarity and interest in this project is such that it could probably be done in a few hours or days at most.**\n",
    "\n",
    "\n",
    "--Adam J Hockenberry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some ipython magic to make life a bit easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic imports, more importantly please be sure to look in \"Shine_Dalgarno_library\" to make sure you have the required imports such that the following cell does not fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Shine_Dalgarno_library\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the basic files depending on which organism/dataset you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For all datasets, use the same aSD sequences in the 5' direction\n",
    "asd_extensions_5_prime = ['-UGGAUCACCUCC.txt', '-GGAUCACCUCC.txt', '-GAUCACCUCC.txt',\\\n",
    "           '-AUCACCUCC.txt','-UCACCUCC.txt','-CACCUCC.txt','-ACCUCC.txt', '-CCUCC.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can comment / uncomment your datasets at will according to which data you'd like to analyze. These aSD extensions were tuned to the organism so if you do not select a valid organism-specific aSD sequence at any point you'll probably get errors. Fragment binding energies for shorter aSD seqs will work for all possible x-mers but for the longer aSD seqs I only computed those necessary to evaluate the specific organisms of interest. I.e. AUCACCUCCUUUCU will not work for E. coli because the E. coli tail is CCUCCUUA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For C. crescentus\n",
    "# teff_file = '../Data/Ccrescentus_rich_teff_cov=75_len=90_ignore=0.json'\n",
    "# mfe_file = '../Data/cis_structure_files/NA1000_JMS_MFE.json'\n",
    "# genome_file = '../Data/genomes/NA1000_JMS.gbk'\n",
    "# asd_extensions_3_prime = ['-CCUCC.txt', '-CCUCCU.txt', '-CCUCCUU.txt', '-CCUCCUUU.txt',\\\n",
    "#            '-CCUCCUUUC.txt', '-CCUCCUUUCU.txt', '-CCUCCUUUCUA.txt', '-CCUCCUUUCUAA.txt', '-CCUCCUUUCUAAG.txt']\n",
    "# asd_extensions_varied = ['-GAUCACCUCCUUU.txt', '-AUCACCUCCUUU.txt', '-UCACCUCCUUU.txt', '-CACCUCCUUU.txt', '-ACCUCCUUU.txt', '-CCUCCUUU.txt',\\\n",
    "#            '-GAUCACCUCCUUUC.txt', '-AUCACCUCCUUUC.txt', '-UCACCUCCUUUC.txt', '-CACCUCCUUUC.txt', '-ACCUCCUUUC.txt', '-CCUCCUUUC.txt',\\\n",
    "#            '-GAUCACCUCCUUUCU.txt', '-AUCACCUCCUUUCU.txt', '-UCACCUCCUUUCU.txt', '-CACCUCCUUUCU.txt', '-ACCUCCUUUCU.txt', '-CCUCCUUUCU.txt',\\\n",
    "#            '-GAUCACCUCCUUUCUA.txt', '-AUCACCUCCUUUCUA.txt', '-UCACCUCCUUUCUA.txt', '-CACCUCCUUUCUA.txt', '-ACCUCCUUUCUA.txt', '-CCUCCUUUCUA.txt']\n",
    "\n",
    "#For E. coli datasets\n",
    "# teff_file = '../Data/Ecoli_rich_teff_cov=75_len=90_ignore=0.json'\n",
    "teff_file = '../Data/Buskirk1_teff.json'\n",
    "# teff_file = '../Data/Buskirk2_teff.json'\n",
    "mfe_file = '../Data/cis_structure_files/oldEcoli_MFE.json'\n",
    "genome_file = '../Data/genomes/oldEcoli.gb'\n",
    "asd_extensions_3_prime = ['-CCUCC.txt', '-CCUCCU.txt', '-CCUCCUU.txt', '-CCUCCUUA.txt', '-CCUCCUUAC.txt']#For E. coli\n",
    "asd_extensions_varied = ['-GAUCACCUCCUUA.txt', '-AUCACCUCCUUA.txt', '-UCACCUCCUUA.txt', '-CACCUCCUUA.txt', '-ACCUCCUUA.txt','-CCUCCUUA.txt',\\\n",
    "           '-GAUCACCUCCUUAC.txt', '-AUCACCUCCUUAC.txt',  '-UCACCUCCUUAC.txt', '-CACCUCCUUAC.txt', '-ACCUCCUUAC.txt','-CCUCCUUAC.txt']\n",
    "\n",
    "#For B. subtilis\n",
    "# teff_file = '../Data/Bsubtilis_rich_teff_cov=75_len=90_ignore=0.json'\n",
    "# mfe_file = '../Data/cis_structure_files/bacillus_MFE.json'\n",
    "# genome_file = '../Data/genomes/bacillus.gb'\n",
    "# asd_extensions_3_prime = ['-CCUCC.txt', '-CCUCCU.txt', '-CCUCCUU.txt', '-CCUCCUUU.txt',\\\n",
    "#            '-CCUCCUUUC.txt', '-CCUCCUUUCU.txt', '-CCUCCUUUCUA.txt', '-CCUCCUUUCUAA.txt', '-CCUCCUUUCUAAG.txt']#For B. subtilis\n",
    "# asd_extensions_varied = ['-GAUCACCUCCUUU.txt', '-AUCACCUCCUUU.txt', '-UCACCUCCUUU.txt', '-CACCUCCUUU.txt', '-ACCUCCUUU.txt', '-CCUCCUUU.txt',\\\n",
    "#            '-GAUCACCUCCUUUC.txt', '-AUCACCUCCUUUC.txt', '-UCACCUCCUUUC.txt', '-CACCUCCUUUC.txt', '-ACCUCCUUUC.txt', '-CCUCCUUUC.txt',\\\n",
    "#            '-GAUCACCUCCUUUCU.txt', '-AUCACCUCCUUUCU.txt', '-UCACCUCCUUUCU.txt', '-CACCUCCUUUCU.txt', '-ACCUCCUUUCU.txt', '-CCUCCUUUCU.txt',\\\n",
    "#            '-GAUCACCUCCUUUCUA.txt', '-AUCACCUCCUUUCUA.txt', '-UCACCUCCUUUCUA.txt', '-CACCUCCUUUCUA.txt', '-ACCUCCUUUCUA.txt', '-CCUCCUUUCUA.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the files above, get the basic dictionaries of gene sequence, 5' UTR, translation efficiency, folding energy, etc.\n",
    "\n",
    "If you're curious how to calculate folding energy files that I called mfe_file above, these functions are included in Shine_Dalgarno_library.py\n",
    "\n",
    "Specifically, refer to the get_structure() function. However note that being able to run this function, or rather RNA_fold_wrapper, might require some optimization on your end to install ViennaRNA and make sure that it's listed in your bash path. Thus, I've simply provided these files for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_dict, five_prime_seq_dict, three_prime_seq_dict = Shine_Dalgarno_library.get_seq_dicts(genome_file)\n",
    "\n",
    "with open(teff_file) as infile:\n",
    "    trans_eff_dict = json.load(infile)\n",
    "print(\"Number of genes with teff data:\", len(trans_eff_dict.keys()))\n",
    "\n",
    "with open(mfe_file) as infile:\n",
    "    mfe_dict = json.load(infile)\n",
    "print(\"Number of genes with mfe data:\", len(mfe_dict.keys()))\n",
    "\n",
    "\n",
    "to_delete = []\n",
    "for gene in trans_eff_dict:\n",
    "    if gene not in seq_dict:\n",
    "        to_delete.append(gene)\n",
    "for gene in to_delete:\n",
    "    del trans_eff_dict[gene]\n",
    "print(\"Number of genes with teff data (after some processing):\", len(trans_eff_dict.keys()))\n",
    "\n",
    "\n",
    "trans_eff_dict_log = {}\n",
    "for i in trans_eff_dict.keys():\n",
    "    trans_eff_dict_log[i] = trans_eff_dict[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the translation efficiency measurements by regressing against folding energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####If you want to correct for the effect of cis-structure run this code\n",
    "trans_eff_dict_structure = Shine_Dalgarno_library.teff_given_structure(trans_eff_dict, mfe_dict)\n",
    "\n",
    "####Otherwise, and I'll admit this is kind of sloppy but meh... just run the below line to pretend that\n",
    "####you corrected for structure even though you didn't. Both analyses showed up in the manuscript/SI\n",
    "# trans_eff_dict_sturcture = trans_eff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a given aSD seq, calculate 1st and 3rd order polynomial fits for a variety of spacings relative to the start codon\n",
    "\n",
    "These json-energyRef-XXXX files are all pre-computed hybridization energies between the sequence referenced in the file name XXXX and all possible equally sized partners (for the longest aSD seqs I didn't actually compute all so these files contain only the computations that were necessary given the genome of that species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energy_base = '../Data/energy_dictionaries/json-energyRef-'\n",
    "asd_of_interest = 'ACCUCCUUA' \n",
    "ending = '.txt'\n",
    "energy_file = energy_base + asd_of_interest + ending\n",
    "print(energy_file)\n",
    "\n",
    "spacing_list = list(range(1, 15))\n",
    "Shine_Dalgarno_library.compare_first_and_third_degree(trans_eff_dict_structure,\\\n",
    "                                                      five_prime_seq_dict,\\\n",
    "                                                      seq_dict,\\\n",
    "                                                      energy_file,\\\n",
    "                                                      spacing_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 1st and 3rd order fits for a single spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energy_base = '../Data/energy_dictionaries/json-energyRef-'\n",
    "asd_of_interest = 'ACCUCCUUA'\n",
    "\n",
    "ending = '.txt'\n",
    "energy_file = energy_base + asd_of_interest + ending\n",
    "\n",
    "spacing = -3\n",
    "\n",
    "poly_1_model, poly_3_model, percents, df = Shine_Dalgarno_library.plot_individual(trans_eff_dict_structure,\\\n",
    "                                                        five_prime_seq_dict, seq_dict, energy_file, spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the various 3' aSD extensions in the form of a heat map\n",
    "### This and following are only showing 3rd order polynomial fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacing_list = list(range(1, 15))\n",
    "energy_file_list = []\n",
    "for i in asd_extensions_3_prime:\n",
    "    for energy_file in glob.glob('../Data/energy_dictionaries/json-energyRef*.txt'):\n",
    "        if i in energy_file:\n",
    "            energy_file_list.append(energy_file)\n",
    "\n",
    "Shine_Dalgarno_library.compare_different_asds(trans_eff_dict_log, five_prime_seq_dict, seq_dict, energy_file_list,\\\n",
    "                                              spacing_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the various 5' aSD extensions in the form of a heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacing_list = list(range(1, 15))\n",
    "energy_file_list = []\n",
    "for i in asd_extensions_5_prime:\n",
    "    for energy_file in glob.glob('../Data/energy_dictionaries/json-energyRef*.txt'):\n",
    "        if i in energy_file:\n",
    "            energy_file_list.append(energy_file)\n",
    "\n",
    "Shine_Dalgarno_library.compare_different_asds(trans_eff_dict_structure, five_prime_seq_dict, seq_dict, energy_file_list,\\\n",
    "                                              spacing_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare some combinations of 5' and 3' extensions in the form of a heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacing_list = list(range(1, 15))\n",
    "energy_file_list = []\n",
    "for i in asd_extensions_varied:\n",
    "    for energy_file in glob.glob('../Data/energy_dictionaries/json-energyRef*.txt'):\n",
    "        if i in energy_file:\n",
    "            energy_file_list.append(energy_file)\n",
    "\n",
    "Shine_Dalgarno_library.compare_different_asds(trans_eff_dict_structure, five_prime_seq_dict, seq_dict, energy_file_list,\\\n",
    "                                              spacing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That was the basic analysis / work flow that was the main point of the paper. Below I'll step through a few other figures that might be useful including analyses of non-ribosomal profiling datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Taniguchi et al data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###These translation efficiency dictionaries were derived from Taniguchi et al. with the files demarcated\n",
    "###as _xxx meaning the x% lowest signal to noise datset. I.e. teff_20.json is the translation efficiencies\n",
    "###of the 20% of genes from this dataset with the highest confidence translation efficiency measurements\n",
    "###not necessarily the highest\n",
    "teff_file_list = ['teff_all.json', 'teff_80.json', 'teff_60.json', 'teff_40.json', 'teff_20.json']\n",
    "teff_file_list = ['../Data/taniguchi_data/'+i for i in teff_file_list]\n",
    "\n",
    "genome_file = '../Data/genomes/oldEcoli.gb'\n",
    "organism_name = 'Escherichia_taniguchi'\n",
    "\n",
    "seq_dict, five_prime_seq_dict, three_prime_seq_dict = Shine_Dalgarno_library.get_seq_dicts(genome_file)\n",
    "\n",
    "first_order_r2 = []\n",
    "third_order_r2 = []\n",
    "percent_increase_list = []\n",
    "\n",
    "for teff_file in teff_file_list:\n",
    "    organism_name = 'Escherichia_taniguchi'+teff_file.split('/')[-1].strip('.json').strip('teff')\n",
    "\n",
    "    with open(teff_file) as infile:\n",
    "        trans_eff_dict = json.load(infile)\n",
    "    print(len(trans_eff_dict.keys()))\n",
    "\n",
    "    to_delete = []\n",
    "    for gene in trans_eff_dict:\n",
    "        if gene not in seq_dict:\n",
    "            to_delete.append(gene)\n",
    "    for gene in to_delete:\n",
    "        del trans_eff_dict[gene]\n",
    "    \n",
    "    with open('../Data/cis_structure_files/oldEcoli_MFE.json') as infile:\n",
    "        mfe_dict = json.load(infile) \n",
    "    \n",
    "    trans_eff_dict_structure = Shine_Dalgarno_library.teff_given_structure(trans_eff_dict, mfe_dict)    \n",
    "    \n",
    "    \n",
    "    energy_base = '../Data/energy_dictionaries/json-energyRef-'\n",
    "    asd_of_interest = 'ACCUCCUUA'\n",
    "    ending = '.txt'\n",
    "    energy_file = energy_base + asd_of_interest + ending\n",
    "\n",
    "\n",
    "    flexibility = 0\n",
    "    spacing = -5\n",
    "\n",
    "    temp_1, temp_3, percent_increase, df = Shine_Dalgarno_library.plot_individual(trans_eff_dict_structure, five_prime_seq_dict, seq_dict, energy_file, spacing)\n",
    "    first_order_r2.append(temp_1.rsquared_adj)\n",
    "    third_order_r2.append(temp_3.rsquared_adj)\n",
    "    percent_increase_list.append(percent_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####All this information is vomited out above if you can find it but here it is if you're interested\n",
    "print(first_order_r2)\n",
    "print(third_order_r2)\n",
    "print(percent_increase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_labels = ['', 'All data\\n (n=1014)', 'Top 80\\%\\n(n=811)', 'Top 60\\%\\n(n=611)', 'Top 40\\%\\n(n=407)', 'Top 20\\%\\n(n=204)']\n",
    "Shine_Dalgarno_library.plot_taniguchi_data(first_order_r2, third_order_r2, percent_increase_list, x_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kosuri data plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Kosuri et al data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Data/kosuri_data/kosuri_data.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_dicty = {}\n",
    "exp_dicty = {}\n",
    "for i in range(111):\n",
    "    seq_dicty[df.loc[i]['RBS'].strip('\\\"')] = str(df.loc[i]['Sequence']).strip('\\\"').replace(' ', '')[:-3].replace('T', 'U')\n",
    "    exp_dicty[df.loc[i]['RBS'].strip('\\\"')] = np.log2(df.loc[i]['mean.xlat'])\n",
    "\n",
    "try:\n",
    "    del seq_dicty['DeadRBS']\n",
    "except KeyError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energy_file = '../Data/energy_dictionaries/json-energyRef-ACCUCCUUA.txt'\n",
    "with open(energy_file) as infile:\n",
    "    energy_dict = json.load(infile)\n",
    "    \n",
    "asd_seq = energy_file.split('-')[-1].strip('.txt')\n",
    "print(asd_seq)\n",
    "spacing = -5\n",
    "gene_binding_dict = {}\n",
    "\n",
    "for i in seq_dicty.keys():\n",
    "    gene_binding_dict[i] = energy_dict[seq_dicty[i][spacing-len(asd_seq):spacing]]\n",
    "#     gene_binding_dict[i] = min([energy_dict[seq_dicty[i][-14:-5]], energy_dict[seq_dicty[i][-15:-6]], energy_dict[seq_dicty[i][-13:-4]]])\n",
    "\n",
    "\n",
    "with open('../Data/kosuri_teffs.json', 'w') as outfile:\n",
    "    json.dump(exp_dicty, outfile)\n",
    "with open('../Data/kosuri_binding_energies.json', 'w') as outfile:\n",
    "    json.dump(gene_binding_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Shine_Dalgarno_library.plot_individual_kosuri(exp_dicty, gene_binding_dict, asd_seq, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Operon analysis\n",
    "This is hacky / kind of incomplete but it basically just will give you back a \"trans_eff_dict\" limited by the operon positions that you want and you can then run this trans_eff_dict through whichever analysis listed above including correcting for structure, etc and perform an analysis split according to operon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(teff_file) as infile:\n",
    "    trans_eff_dict = json.load(infile)\n",
    "print(\"Number of genes with teff data:\", len(trans_eff_dict.keys()))\n",
    "\n",
    "to_delete = []\n",
    "for gene in trans_eff_dict:\n",
    "    if gene not in seq_dict:\n",
    "        to_delete.append(gene)\n",
    "for gene in to_delete:\n",
    "    del trans_eff_dict[gene]\n",
    "print(\"Number of genes with teff data (after some processing):\", len(trans_eff_dict.keys()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_csv('../Data/operons/ccrescentus_DOOR_operons.csv', sep='\\t', index_col='id')\n",
    "# df = pd.read_csv('../Data/operons/bsub_DOOR_operons.csv', sep='\\t', index_col='id')\n",
    "df = pd.read_csv('../Data/operons/ecoli_DOOR_operons.csv', sep='\\t', index_col='id')\n",
    "operonDict = {}\n",
    "for index in df.index:\n",
    "    for number, synonym in enumerate(df.loc[index]['synonyms'].split(';')):\n",
    "        if synonym.strip() in operonDict.keys():\n",
    "            operonDict[synonym.strip()] = 'ambiguous'\n",
    "        elif number == 0:\n",
    "            operonDict[synonym.strip()] = 'First'\n",
    "        else:\n",
    "            operonDict[synonym.strip()] = 'Late'\n",
    "            \n",
    "print(len(operonDict.keys()))\n",
    "print(set(operonDict.values()))            \n",
    "\n",
    "for gene in list(trans_eff_dict.keys()):\n",
    "    if gene not in operonDict.keys():\n",
    "        del trans_eff_dict[gene]\n",
    "    elif operonDict[gene] != 'First': #####Choose/toggle operon positions here\n",
    "#     elif operonDict[gene] != 'Late': ######And here\n",
    "        del trans_eff_dict[gene]\n",
    "print(len(trans_eff_dict.keys()))\n",
    "\n",
    "# organism_name = organism_name + 'first_in_TU'\n",
    "organism_name = organism_name + 'middle_of_TU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "246px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
